%\documentclass[11pt]{article}
\documentclass{llncs}

\usepackage{graphicx}
\usepackage{amsmath} 

\pagenumbering{arabic}
\usepackage{lineno}

\newcommand{\integ}{{\sf int}}
\newcommand{\listint}{{\sf listint}}
\newcommand{\other}{{\sf other}}
\newcommand{\true}{\mathsf {true}}
\newcommand{\false}{\mathsf {false}}
\newcommand{\Res}{{\sf Res}}
\newcommand{\Bin}{{\sf Bin}}
\newcommand{\Dep}{{\sf Dep}}
\newcommand{\g}{{\sf g}}
\newcommand{\nong}{{\sf ng}}
\newcommand{\OL}{{\cal O}}
%\newcommand{\mgu}{{\sf mgu}}
\newcommand{\M}{{\sf M}}
\newcommand{\R}{{\cal R}}
\newcommand{\A}{{\cal A}}

\newcommand{\B}{{\cal B}}
\newcommand{\C}{{\cal C}}
\newcommand{\D}{{\cal D}}
\newcommand{\X}{{\cal X}}
\newcommand{\V}{{\cal V}}
\newcommand{\Q}{{\cal Q}}
\newcommand{\F}{{\sf F}}
\newcommand{\N}{{\cal N}}
\newcommand{\Lang}{{\cal L}}
\newcommand{\powerset}{{\cal P}}
\newcommand{\FTA}{{\cal FT\!A}}
\newcommand{\Term}{{\sf Term}}
\newcommand{\Empty}{{\sf empty}}
\newcommand{\nonEmpty}{{\sf nonempty}}
\newcommand{\compl}{{\sf complement}}
\newcommand{\args}{{\sf args}}
\newcommand{\preds}{{\sf preds}}
\newcommand{\gnd}{{\sf gnd}}
\newcommand{\lfp}{{\sf lfp}}
\newcommand{\psharp}{P^{\sharp}}
\newcommand{\minimize}{{\sf minimize}}
\newcommand{\headterms}{\mathsf{headterms}}
\newcommand{\solvebody}{\mathsf{solvebody}}
\newcommand{\solve}{\mathsf{solve}}
\newcommand{\fail}{\mathsf{fail}}
\newcommand{\member}{\mathsf{memb}}
\newcommand{\ground}{\mathsf{ground}}



\newcommand{\transitions}{\mathsf{transitions}}
\newcommand{\nonempty}{\mathsf{nonempty}}
\newcommand{\dom}{\mathsf{dom}}


\newcommand{\Args}{\mathsf{Args}}
\newcommand{\id}{\mathsf{id}}
\newcommand{\type}{\tau}
\newcommand{\restrict}{\mathsf{restrict}}
%\newcommand{\any}{\mathsf{any}}
\newcommand{\any}{\top}
\newcommand{\dyn}{\top}
\newcommand{\dettypes}{{\sf dettypes}}
\newcommand{\Atom}{{\sf Atom}}


\newcommand{\vars}{\mathsf{vars}}
\newcommand{\Vars}{\mathsf{Vars}}
\newcommand{\range}{\mathsf{range}}
\newcommand{\varpos}{\mathsf{varpos}}
\newcommand{\varid}{\mathsf{varid}}
\newcommand{\argpos}{\mathsf{argpos}}
\newcommand{\elim}{\mathsf{elim}}
\newcommand{\pred}{\mathsf{pred}}
\newcommand{\predfuncs}{\mathsf{predfuncs}}
\newcommand{\project}{\mathsf{project}}
\newcommand{\reduce}{\mathsf{reduce}}
\newcommand{\positions}{\mathsf{positions}}
\newcommand{\contained}{\preceq}
\newcommand{\equivalent}{\cong}
\newcommand{\unify}{{\it unify}}
\newcommand{\Iff}{{\rm iff}}
%\newcommand{\And}{{\rm and}}
\newcommand{\Where}{{\rm where}}
\newcommand{\State}{\mathsf{S}}
\newcommand{\qmap}{{\sf qmap}}
\newcommand{\fmap}{{\sf fmap}}
\newcommand{\ftable}{{\sf ftable}}
\newcommand{\Qmap}{{\sf Qmap}}
\newcommand{\states}{{\sf states}}
\newcommand{\head}{\tau}

\newcommand{\keyword}[1]{\mathsf{#1}}
\newcommand{\SKIP}{\keyword{skip}}
\newcommand{\RET}[1]{\keyword{return}\,#1}
\newcommand{\ASG}[2]{#1 := #2}
\newcommand{\SEQ}[2]{#1\,{;}\,#2}
\newcommand{\IFNZ}[3]{\keyword{if} \,(#1)\, #2\,\keyword{else}\,#3}
\newcommand{\FOR}[4]{\keyword{for} \,(#1\,#2\,#3)\, #4}
\newcommand{\WHILE}[2]{\keyword{while} \,(#1)\, #2}

\newcommand{\VAR}[1]{\keyword{var}(#1)}
\newcommand{\VAL}[1]{\keyword{val}(#1)}
\newcommand{\LAM}[2]{\keyword{lam} (#1,#2)}
\newcommand{\APP}[2]{\keyword{app} (#1,#2)}
\newcommand{\APPP}[2]{\keyword{app2} (#1,#2)}
\newcommand{\CLO}[3]{\keyword{clo} (#1,#2,#3)}



\usepackage{listings} 
\usepackage{courier}
\lstset{
%
%
  %
  stringstyle=\ttfamily,
  showstringspaces = false,
  basicstyle=\linespread{0.9}\footnotesize\ttfamily,
  commentstyle=\small\emph,
  keywordstyle=\small\bfseries,
  %
  numbers=none,
  mathescape=true,
  numbersep=3pt,
  numberstyle=\tiny,
  numberfirstline=true,
  breaklines=true,
  language=C,
  xleftmargin=1em,
  morekeywords={if,then,else,do,return,length,let,seq,asg,function,call,ret,ifthenelse,block,skip,app,lam,app2,var,val,clo},
  deletekeywords={static,struct,call},
  columns=[l]flexible
}

\def\ll{[\![}
\def\rr{]\!]}

\newcommand{\todo}[1]{\textbf{**}\marginpar{\fbox{
\begin{minipage}{\oddsidemargin}
\textsf{{\small#1}}
\end{minipage}
}}}

\newcommand{\sset}[2]{\left\{~#1  \left|
                               \begin{array}{l}#2\end{array}
                          \right.     \right\}}


\newcommand{\qin}{\hspace*{0.15in}}
\newenvironment{SProg}
     {\begin{small}\begin{tt}\begin{tabular}[t]{l}}%
     {\end{tabular}\end{tt}\end{small}}
\def\anno#1{{\ooalign{\hfil\raise.07ex\hbox{\small{\rm #1}}\hfil%
        \crcr\mathhexbox20D}}}


\title{Transforming big-step to small-step semantics using interpreter specialisation}


\author{John P. Gallagher \thanks{Email. \texttt{jpg@ruc.dk}}\inst{1}\inst{2}
\and
Manuel Hermenegildo\inst{2}  \and Jos\'e Morales
\inst{2} \and Pedro L\'opez Garc\'ia\inst{2} 
}

\institute{Roskilde University, Denmark
\and
IMDEA Software Institute, Madrid, Spain}


\begin{document}
\maketitle
\input{abstract}

\pagestyle{plain}

\linenumbers
\pagestyle{myheadings}

\section{Introduction}

The goal of this work is to transform big-step operational semantics to small-step operational semantics.
This has previously been studied \cite{VeselyF19,HuizingKK10,AmbalLSN22}.
%as has the related problem of deriving abstract machines from big-step semantics \cite{Ager}. 
The main novelty is the method, which we consider to be more
direct and transparent than previous approaches.  We formulate the transformation as the specialisation of a
linearising interpreter for big-step semantic rules.  Once a suitable interpreter has been written, in which the general
definition of a ``small step" has been encoded (see Section \ref{small-step-interp}), the transformation
consists of partially evaluating it with respect to given big-step semantics.  The specialised interpreter contains the 
small-step transition rules, 
with minor syntactic modification. We describe experiments using an off-the shelf partial evaluator 
for logic programs \cite{Logen} (Section \ref{examples}).
\section{Background}\label{background}

\paragraph{Operational Semantics.}
Natural semantics (NS) was proposed by Kahn in the 
1980s \cite{Kahn87}; the name indicates an analogy with natural deduction. 
Structural operational semantics (SOS) was developed by Plotkin \cite{Plotkin1981,Plotkin04,Plotkin04a}.  
The motivation of SOS was to define
``machine-like" execution of programs, but in a syntax-directed style, omitting all unnecessary details of
the machine.  Both styles have their advantages, which we do not discuss here.

We use the nicknames \emph{big-step} and \emph{small-step} for NS and SOS respectively;  they neatly
express the difference between NS and SOS.  Both approaches define the behaviour of a program
as runs in a transition system. The system states have the form $\langle s, \sigma\rangle$ where $s$ is an
expression (such as a statement) and $\sigma$ is a program environment, such as memory state; 
sometimes $s$ is omitted when it is empty
or associated with a final state.  

In big-step semantics, transitions are of the form $\langle s, \sigma\rangle \Longrightarrow \sigma'$, or 
$\langle s, \sigma\rangle \Longrightarrow s'$ depending on the language being defined.
which means that $s$ is completely evaluated in $\sigma$, terminating in final state $\sigma'$ or value $s'$.
%
By contrast, in small-step semantics, a transition has the form $\langle s, \sigma\rangle \Rightarrow \langle s',\sigma'\rangle$, 
which defines a single step
from $s$ in environment $\sigma$ to the \emph{next} expression $s'$ and next environment $\sigma'$. We may also have a transition
$\langle s, \sigma\rangle \Rightarrow \sigma'$ or $\langle s, \sigma\rangle \Rightarrow s'$ for the case that $s$ terminates in one step.
A computation or run is defined as a 
chain of small steps.  Note that we use $\Longrightarrow$ and $\Rightarrow$ for big and small-step transitions respectively.

\paragraph{Interpreter specialisation.}
The idea of specialising a program with respect to partial input,  known as program specialisation, partial evaluation or mixed computation, 
originated in the 1960s and 1970s \cite{Lombardi67,Futamura,BeckmanHOS76,Ershov77}.  
In particular, the specialisation of a program interpreter with respect to an object program,  but with unknown
program state (known as the first Futamura projection) is analogous to compilation of the object 
program into the language in which the interpreter is written \cite{Futamura}.  
When the interpreter is written in the same language as that of the object program,
the result of specialisation may be viewed as a source transformation of the object program 
(whereas it is in fact a transformation of the interpreter). 
The transformation can be regarded as the imposition of (possibly non-standard) semantics encoded in the
interpreter onto the object program. 
This idea was exploited to transform programs \cite{Gallagher-86,Turchin85,GluckJ94,Jones04,GiacobazziJM12}, and can result in deep changes in program structure, 
possibly yielding superlinear speedups, in contrast to partial evaluation itself, which gives only linear speedups and does not fundamentally alter program
structure.  Some established program transformations
can be realised as interpreter specialisation.  A transformation technique for logic programs with the similar 
aim of changing the semantics, \emph{compiling control} \cite{Bruynooghe-DeSchreye-Krekels},
has also been shown to be realisable as interpreter specialisation \cite{NysS18}.

The idea and power of transformation by interpreter specialisation are thus well known, yet its potential has not been fully realised, probably due to the 
fact that effective specialisation of complex interpreters is beyond the power of general purpose program specialisers and needs 
further research.  Our current work offers further evidence of its versatility and effectiveness.

\paragraph{Horn clause representation of semantics and interpreters.}
Both big-step and small-step transitions have the form of rules with premises and conclusion, typically written in the following form.
\[
\dfrac{\mathit{premises}} 
{\mathit{conclusion}} 
~~~~\mathrm{if }~ \mathit{condition}
\]
With a suitable encoding of syntactic objects and environments as first-order terms, this is a first-order logic implication
$\mathit{premises} \wedge \mathit{condition} \rightarrow \mathit{conclusion}$ 
The conclusion is an atomic formula
(a big- or small-step transition) so assuming that the premises and conditions are conjunctions,
it is a Horn clause.

The close connection between transition rules and Horn clauses, and hence to the logic programming language Prolog, 
was noticed by Kahn and his co-workers and exploited in
the Typol tool \cite{Despeyroux1984}. 
Similarly, small step transition rules, together with a rule specifying a run of
small-step transitions, can also be written as Horn clauses and used to execute programs.

Interpreters for logic programs can themselves be written as logic programs, where the program being interpreted 
is represented in some suitable way as a data structure in the interpreter (see \cite{Hill-Gallagher-Handbook,HillL88} for a discussion
of representations.)

\paragraph{Summary of our approach.}  Let $I(x,y)$ be a logic program implementing an interpreter for a set of
big-step semantics rules $x$ and an object program $y$. $I$ is written in a linear, small-step style (see next section).  
Let logic program $B$ be the big-step semantics
for some programming language, and let $\lceil B \rceil$ be the representation of $B$ in the interpreter.  Then we specialise 
$I(\lceil B \rceil,y)$.  The resulting specialised interpreter $I_B(y)$ is a logic program containing (after some minor syntactic modification) 
the small-step semantic rules
corresponding to $B$.

In the following, we use Prolog syntax and teletype font for Horn clauses.

\section{A small-step interpreter for big-step semantics}\label{small-step-interp}

\paragraph{Linear interpretation.}  Figure \ref{fig:linear-interp} shows the main clauses of a linear interpreter for any Horn clause program $P$.  
The predicate \texttt{clause(Head,Body)} is used to access the clauses of $P$.  The predicate \texttt{run(As)} has as argument a stack of atoms, and
at each step the atom  \texttt{A} at the top of the stack is replaced by the (instance of the) body of a clause whose head unifies with \texttt{A}.
(We ignore for now the treatment of builtin predicates such as arithmetic predicates).
To run a goal \texttt{A} in $P$ we execute \texttt{run([A])} in the interpreter.  
Correctness of the interpreter follows from the soundness and completeness of linear resolution.
\begin{figure}
\begin{tabular}{l}
\begin{lstlisting}
run([A|As]) :-  clause(A,B), append(B,As,As1), run(As1).
run([]).
\end{lstlisting}
\end{tabular}
\caption{Clauses from a linear interpreter.}\label{fig:linear-interp}
\end{figure}

This interpreter could be specialised with respect to a given $P$, transforming $P$ to continuation-passing
style, also known as binary logic programs \cite{Demoen92}.

\paragraph{Linear interpreter for big-step semantics.} 
Our interpreter for big-step semantics is a linear interpreter of big-step semantics; however,  
instead of performing just one resolution step on each cycle of the interpreter,
as in Figure \ref{fig:linear-interp}, we wish to execute a number of resolution steps corresponding to whatever we define to be a ``small step" in the 
program execution.  The main interpreter loop thus has the form shown in Figure \ref{fig:linear-bigstep}.
\begin{figure}
\begin{tabular}{l}
\begin{lstlisting}
run([A|As]) :- smallStep(A,As,As1), run(As1).
run([]).
\end{lstlisting}
\end{tabular}
\caption{Core of the linear big-step interpreter.}\label{fig:linear-bigstep}
\end{figure}

The definition of the interpreter predicate \texttt{smallStep} is the crucial part of the whole interpreter.
We now look more closely at the form of big-step transition rules, which will lead us to its definition. 
Following \cite{NielsonN1992}, we take the general form of big-step rules to
be as follows.
\[
\dfrac{\langle s_1, \sigma_1\rangle \Longrightarrow \sigma'_1, \ldots, \langle s_n, \sigma_n\rangle \Longrightarrow \sigma'_n}
{\langle s, \sigma\rangle \Longrightarrow \sigma'} 
~~~~\mathrm{if }~ c
\]
This will be rendered as a Horn clause as follows.
\begin{lstlisting}
bigstep(S,M0,M01):-C,bigstep(S1,M1,M11),...,bigstep(Sn,Mn,Mn1)
\end{lstlisting}
If the premises are empty ($n=0$) we call the rule an \emph{axiom}.  The syntax elements appearing as $s$ in the conclusion 
are of the form $s=f(s'_1,\ldots,s'_k)$, where $s'_1,\ldots,s'_k$ are the immediate constituents of $s$.  Note that the immediate constituents 
are not necessarily the same as the $s_1,\ldots,s_n$ in the premises.  We assume that each syntax constructor $f$ appears in the conclusion
of one or more rules, and that a constructor does not appear in the conclusion of both an axiom and non-axiom. Given a syntax term $s=f(t_1,\ldots,t_k)$,
we call $s$ a \emph{leaf} if $f$ appears in the conclusion of one or more axioms, otherwise $s$ is called a \emph{non-leaf}.

\paragraph{Definition of a small step.} We now proceed to define \texttt{smallStep} in stages, to motivate its construction.
The first version is shown in Figure \ref{fig:linear-smallstep}.
A small step is the application of one big-step axiom.  
The application of the non-axioms may be seen as reductions of the syntax
term into its constituent terms (or other terms constructed from them), and hence does not actually \emph{do} anything computational.
Our first definition of the \texttt{smallStep} relation is thus to apply rules so long as the top of stack is a non-leaf; when 
the top of stack is a leaf, it executes the condition of the axiom, represented by the call \texttt{eval(Bs)}, and terminates.  
Note that \texttt{smallStep}
is a recursive predicate, and its execution may take many step, depending on the depth of the syntax term.

\begin{figure}
\begin{tabular}{l}
\begin{lstlisting}
smallStep(bigstep(A,St,St1),As,As) :- 
    leaf(A), clause(bigstep(A,St,St1), Bs), eval(Bs).
smallStep(bigstep(A,St,St1),As,As1) :- 
    nonLeaf(A), clause(bigstep(A,St,St1), [B|Bs]),
    append([B|Bs],As,[B|Bs1]),
    smallStep(B,Bs1,As1).
\end{lstlisting}
\end{tabular}
\caption{First definition of a small step.}\label{fig:linear-smallstep}
\end{figure}

Consider now the second clause for \texttt{smallStep}, handling a non-leaf.  The clause to be applied has at least one
call to \texttt{bigstep} in the body, since it is not an axiom. Hence we can consider the first such call (the variable \texttt{B} in the clause).
If it is a leaf, \texttt{smallStep} terminates on the next step, otherwise it is a non-leaf and \texttt{smallStep} will be called recursively.
This lookahead is needed to construct recursive small-step rules handling the non-leaf constructs. Adding this to the definition of
\texttt{smallStep}, we get the code shown in Figure \ref{fig:linear-nextstep}.

\begin{figure}
\begin{tabular}{l}
\begin{lstlisting}
smallStep(bigstep(A,St,St1),As,As) :- 
    leaf(A), clause(bigstep(A,St,St1), Bs), eval(Bs).
smallStep(bigstep(A,St,St1),As,As1) :- 
    nonLeaf(A), clause(bigstep(A,St,St1), [B|Bs]),
    append([B|Bs],As,[B|Bs1]),
    nextStep(B,Bs1,As1).
    
nextStep(A,As,As) :-
    leaf(A), smallStep(A,As,As).
nextStep(A,As,As1) :-
    nonLeaf(bigstep(A,St0,St1)),
    smallStep(bigstep(A,St0,St1),As,As1).
\end{lstlisting}
\end{tabular}
\caption{Expanded small step definition, with next step lookahead.}\label{fig:linear-nextstep}
\end{figure}

\begin{figure}
\begin{tabular}{l}
\begin{lstlisting}
smallStep(A,[]) :-
	leaf(A),clause(_,A,Bs),callPreds(Bs).
smallStep(bigstep(A,St0,St1),As1) :-
	nonLeaf(bigstep(A,St0,St1)),
	clause(K,bigstep(A,St0,St1),[B|Bs]),
	evalConditions([B|Bs],[B1|Bs1]),
	nextStep([B1|Bs1],K,As1).	
nextStep([A|Bs],_,Bs1) :-
	leaf(A), evalConditions(Bs,Bs1),smallStep(A,[]).
nextStep([bigstep(A,St0,St1)|Bs],K,[H]) :-
	nonLeaf(bigstep(A,St0,St1)),
	smallStep(bigstep(A,St0,St1),[bigstep(U,V,W)]),
	tryFold(K,H,[bigstep(U,V,W)|Bs]).
	
tryFold(_,B1,[B1]).
tryFold(K,H,[B1|Bs]) :-
	Bs \== [], clause(K,H,[B1|Bs]).
\end{lstlisting}
\end{tabular}
\caption{Definition of a small step, with folding of the stack.}\label{fig:linear-fold}
\end{figure}

\paragraph{Folding to eliminate the stack.}  So far, the interpreter still handles a stack; but small-step semantics
uses no stack.  We now eliminate the stack;  more precisely, we apply folding so that it
contains at most one call to \texttt{bigstep}.

Consider again the general form of a big-step rule with $n$ premises, where $n>0$ (a non-axiom).  For the moment,
assume that $n\le 2$.  We discuss the general case later. The constructor $f$ is shown in
the conclusion.  
\[
\dfrac{\langle s_1, \sigma_1\rangle \Longrightarrow \sigma'_1 ~~~\langle s_2, \sigma_2\rangle \Longrightarrow \sigma'_2}
{\langle f(s'_1,\ldots,s'_k), \sigma\rangle \Longrightarrow \sigma'} 
~~~~\mathrm{if }~ c
\]



Small step evaluation of such a rule evaluates the arguments from left to right, applying small steps to the first premise until it
is completed, then the second and so on. For example, consider the imperative statement $s_1;s_2$. Execution of the
first premise may take several small steps: $\langle s_1, \sigma_1\rangle, \langle s_{1,1}, \sigma_{1,1}\rangle, \langle s_{1,2}, \sigma_{1,2}\rangle, \ldots \sigma_2$.
Execution then moves to $\langle s_2, \sigma_2\rangle$.  
In small step execution, the context of the execution of the first component is
maintained by reusing the syntactic functor in the conclusion. Thus the small-step execution of $s_1;s_2$ follows the sequence
$\langle s_1;s_2, \sigma_1\rangle, \langle s_{1,1};s_2, \sigma_{1,1}\rangle, \langle s_{1,2};s_2, \sigma_{1,2}\rangle, \ldots \langle s_2,\sigma_2\rangle,\ldots$.

The construction of the context of the rule conclusion is achieved in the interpreter by folding the current stack of goals using the 
clause that was used to produce it. Either the stack contains only one goal, in which case no folding is needed, or
the stack height is two and so has the form required to fold with the rule clause.
Adding the folding operation gives the code for \texttt{smallStep} shown in Figure \ref{fig:linear-fold}. 
Note that the second argument of \texttt{smallStep} in the previous figure is always \texttt{[]}; we
omit it leaving \texttt{smallStep} with only two arguments.

\begin{figure}
\[
\begin{array}{l|l}
 \dfrac{ } 
{\langle \ASG{x}{e}, \sigma \rangle \Longrightarrow \sigma[x/v]}
 ~~~\text{if } V e \sigma = v~


&~~~
\dfrac{\langle s_1, \sigma \rangle \Longrightarrow \sigma' } 
{\langle \IFNZ{b}{s_1}{s_2}, \sigma \rangle \Longrightarrow \sigma'}
 ~~~~~~~\text{if } V b \sigma = \true\\
 \\
\dfrac{\langle s_1, \sigma \rangle \Longrightarrow \sigma' ~~~~\langle s_2, \sigma' \rangle \Longrightarrow \sigma''} 
{\langle \SEQ{s_1}{s_2}, \sigma \rangle \Longrightarrow \sigma''}~~~
&~~~
\dfrac{\langle s_2, \sigma \rangle \Longrightarrow \sigma' } 
{\langle \IFNZ{b}{s_1}{s_2}, \sigma \rangle \Longrightarrow \sigma'}
 ~~~~~~~\text{if } V b \sigma = \false\\
 \\
 \dfrac{} 
{\langle \SKIP, \sigma \rangle \Longrightarrow \sigma}
 ~
&~~~
\dfrac{\langle \IFNZ{b}{s;\WHILE{b}{s}}{\SKIP}, \sigma \rangle \Longrightarrow \sigma'} 
{\langle \WHILE{b}{s}, \sigma \rangle \Longrightarrow \sigma'}
\\
\\
&
\dfrac{\langle \mathit{init}, \sigma \rangle \Longrightarrow \sigma' ~~~~\langle \WHILE{b}{\SEQ{s}{\mathit{inc}}}, \sigma' \rangle \Longrightarrow \sigma''} 
{\langle \FOR{\mathit{init}}{b}{\mathit{inc}}{s}, \sigma \rangle \Longrightarrow \sigma''}
\\
 \end{array}
\]
\caption{Big-step rules for a small imperative language.}\label{big-step-trans}
\end{figure}

\section{Examples}\label{examples}

\paragraph{Simple imperative language.} 
Figure \ref{big-step-trans} shows the big-step semantics for a small imperative language containing assignments, statement composition,
if-then-else, while and for statements.  We assume a function $V$ that evaluates expressions and conditionals in a state.  
Specialising our small-step interpreter (using {\sc  Logen} \cite{Logen}) with respect to these rules gives the output shown in Figure \ref{small-step-while}. 
While a few of the
arguments are redundant, the small-step rules shown in Figure \ref{small-step-rules} can be directly extracted.  The first clause for \texttt{while}
(the 7th clause for \texttt{smallStep}) contains the body goal \texttt{leaf5(bigstep(ifthenelse(...))} which fails and so that clause can be eliminated.
In general, the control of the partial evaluator {\sc  Logen}  is a balance between unfolding too much and unfolding too little, so the occasional 
case of ``dead-end" clauses
are eliminated by post-processing. The rules are similar to textbook small-step semantics for imperative constructs. 
We chose to define $\keyword{while}$ 
by reducing it to $\keyword{if}$; a direct interpretation of $\keyword{while}$ would have given the familiar cases based on the value of the loop condition. 
The rules for $\keyword{for}$ are interesting, repeatedly reducing
the $\mathit{init}$ statement, moving to a $\keyword{while}$ statement when $\mathit{init}$ is complete.  



\paragraph{Call-by-value semantics for $\lambda$-calculus.} This example (shown in Appendix \ref{lambda-ex}) is taken from Vesely and Fisher's work \cite{VeselyF19}.
It illustrates the treatment of
rules that contain more than two big steps in the premises (the rule for application $\mathrm{app}(e_1,e_2))$.  As discussed above, the stack cannot contain more
than one call;  to handle the three rule premises (which would cause the stack to contain the two remaining premises)
we introduce a new syntax constructor $\mathrm{app2}$ which gathers all the calls after the first. (Vesely and Fisher's method also introduces a new constructor).
We think of
this as creating one big step for the rest of the premises after the first. In our example we have done this manually, so that all the big-step rules contain no 
more than two 
premises.  However, this could potentially be built into the interpreter.  


\begin{figure}
\begin{tabular}{l}
\begin{lstlisting}
smallStep(skip,A,A,[]).
smallStep(asg(var(D),C),A,B,[]) :- eval3(C,A,E,F),eval4(D,F,E,B).
smallStep(seq(C,D),A,B,[bigstep(D,E,B)]) :-
    leaf5(bigstep(C,A,E)), smallStep(C,A,E,[]).
smallStep(seq(C,D),A,B,[bigstep(seq(F,D),E,B)]) :-
    nonLeaf6(bigstep(C,A,G)), smallStep(C,A,G,[bigstep(F,E,G)]).
smallStep(ifthenelse(C,D,_),A,B,[bigstep(D,E,B)]) :-
    leaf5(controlExpr(C,A,E,1)),smallStep2(C,A,E,1,[]).
smallStep(ifthenelse(C,_,D),A,B,[bigstep(D,E,B)]) :-
    leaf5(controlExpr(C,A,E,0)),smallStep2(C,A,E,0,[]).
smallStep(while(C,D),A,B,[]) :-
    leaf5(bigstep(ifthenelse(C,seq(D,while(C,D)),skip),A,B)),
    smallStep(ifthenelse(C,seq(D,while(C,D)),skip),A,B,[]).
smallStep(while(C,D),A,B,[bigstep(E,F,G)]) :-
    nonLeaf6(bigstep(ifthenelse(C,seq(D,while(C,D)),skip),A,B)),
    smallStep(ifthenelse(C,seq(D,while(C,D)),skip),A,B,[bigstep(E,F,G)]).
smallStep(for(C,D,E,F),A,B,[bigstep(while(D,seq(F,E)),G,B)]) :-
    leaf5(bigstep(C,A,G)),smallStep(C,A,G,[]).
smallStep(for(C,D,E,F),A,B,[bigstep(for(H,D,E,F),G,B)]) :-
    nonLeaf6(bigstep(C,A,I)),smallStep(C,A,I,[bigstep(H,G,I)]).

\end{lstlisting}
\end{tabular}
\caption{Small step clauses for statements, in the specialised interpreter.}\label{small-step-while}
\end{figure}

\begin{figure}
\[
\begin{array}{l|l}
 \dfrac{ } 
{\langle \ASG{x}{e}, \sigma \rangle \Rightarrow \sigma[x/v]}
 ~~~~~~~~~~~\text{if } V e \sigma = v~~~

&~

\dfrac{} 
{\langle \SKIP, \sigma \rangle \Rightarrow \sigma}
\\
\\
\dfrac{} 
{\langle \IFNZ{b}{s_1}{s_2}, \sigma \rangle \Rightarrow \langle s_1,\sigma'\rangle}
 ~\text{if } V b \sigma = \true
&~
\dfrac{\langle s_1, \sigma \rangle \Rightarrow \sigma' } 
{\langle \SEQ{s_1}{s_2}, \sigma \rangle \Rightarrow \langle s_2 \sigma'\rangle}~~~
\\
 \\
 \dfrac{} 
{\langle \IFNZ{b}{s_1}{s_2}, \sigma \rangle \Rightarrow \langle s_2,\sigma'\rangle}
 ~\text{if } V b \sigma = \false
&~
 \dfrac{\langle s_1, \sigma \rangle \Rightarrow \langle s_1', \sigma'\rangle} 
{\langle \SEQ{s_1}{s_2}, \sigma \rangle \Rightarrow \langle \SEQ{s_1'}{s_2}, \sigma'\rangle}~~~
 ~

\\
 \\
\dfrac{\langle \mathit{init}, \sigma \rangle \Rightarrow \sigma' } 
{\langle \FOR{\mathit{init}}{b}{\mathit{inc}}{s}, \sigma \rangle \Rightarrow \langle \WHILE{b}{\SEQ{s}{\mathit{inc}}}, \sigma' \rangle}
 ~
&~
\dfrac{\langle \IFNZ{b}{s;\WHILE{b}{s}}{\SKIP}, \sigma \rangle \Rightarrow \langle s_1,\sigma'\rangle} 
{\langle \WHILE{b}{s}, \sigma \rangle \Rightarrow \langle s_1,\sigma'\rangle}
\\
\\
 \dfrac{\langle \mathit{init}, \sigma \rangle \Rightarrow\langle \mathit{init}', \sigma' \rangle } 
{\langle \FOR{\mathit{init}}{b}{\mathit{inc}}{s}, \sigma \rangle \Rightarrow \langle \FOR{\mathit{init}'}{b}{\mathit{inc}}{s}, \sigma' \rangle}
 ~
&~
\\
 \end{array}
\]
\caption{Extracted small-step rules for a small imperative language.}\label{small-step-rules}
\end{figure}

\section{Related Work}
Vesely and Fisher \cite{VeselyF19} start from an evaluator for big-step semantics 
for a given language and then
transform it in (ten) stages to a small-step evaluator.  While our generic big-step interpreter embodies some of the same transformations (for instance,
continuation-passing transformation corresponds closely to ``linear" interpretation), some of their transformations are more low-level,
and are subsumed by standard features of partial evaluation (for instance, argument lifting).  We also exploit the uniform 
representation of semantics and the interpreter as Horn clauses and the term representation of object programs in the interpreter to avoid
explicit defunctionalisation or continuations-to-terms. Overall, we claim that interpreter specialisation gives a more direct and
transparent approach. Its correctness depends on validating the interpreter (which can be run on code examples)
and the correctness of the partial evaluator, an established and well-tested tool.  Furthermore, the definition of what is a small step can be
modified;  for example, evaluation of conditionals in $\keyword{if}$ statements could be done in small steps instead of as an atomic operation
by a small modification of the interpreter.

Ambal \emph{et al.} \cite{AmbalLSN22} describe a transformation that also starts from a continuation-passing transformation. To eliminate the 
continuation stack they introduce a new syntax constructor for each continuation, somewhat as we propose for the case of more than two premises.
In other words, they do not fold the stack with the rule used to create it.  This approach could also be implemented via interpreter specialisation
and might be more general than our folding approach;  we have not investigated whether there are limits to the cases where folding can be applied.

Huizing \emph{et al.} \cite{HuizingKK10} describe a direct transformation of big-step rules - so their approach is not explicitly based
on an interpreter.  Ager \cite{Ager04} defines a transformation from L-attributed big-step rules to abstract machines, a closely related problem.  His is
also a direct transformation rather than based on an explicit interpreter.  

\bibliographystyle{plain}
\bibliography{refs}

\newpage
\appendix
\input{appendix1}
\newpage
\input{appendix2}

\end{document}
